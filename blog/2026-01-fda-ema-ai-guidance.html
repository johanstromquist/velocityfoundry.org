<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="FDA and EMA just released joint guidance on AI in drug development. In a world where the US is withdrawing from everything, these two agencies chose to collaborate. The principles they landed on aren't new—they're the same standards we've always had.">
    <title>10 Principles, Zero Excuses: What FDA/EMA's AI Guidance Actually Means - Velocity Foundry</title>
    <link rel="icon" type="image/x-icon" href="../favicon.ico">
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="../assets/css/animations.css">
    <link rel="stylesheet" href="../assets/css/blog.css">
</head>
<body>
    <!-- Navigation (injected dynamically) -->
    <div id="blog-nav"></div>

    <!-- Post Hero (injected dynamically from posts.js) -->
    <div id="blog-hero"></div>

    <!-- Post Content -->
    <article class="container" style="padding: 0 var(--space-md) var(--space-xl);">
        <div class="post-nav" style="border-bottom: 2px solid var(--gray-200); padding-bottom: var(--space-sm); margin-bottom: var(--space-lg);" id="blog-top-nav"></div>

        <div class="post-content">

            <p>A few weeks ago, the United States launched a military operation to capture the sitting president of Venezuela and fly him out of the country. When asked about it, President Trump said "kidnapping is not really a bad word."</p>

            <p>The US has withdrawn from 66 international organizations since January. Trade wars with Canada and Mexico. Threats over Greenland. Global polling now shows China viewed as a more stabilizing presence than America.</p>

            <p>Against this backdrop, FDA and EMA just released joint guidance on AI in drug development.</p>

            <p>I find that remarkable.</p>

            <h2>When Agencies Choose to Collaborate</h2>

            <p>FDA and EMA don't often release joint guidance. They've had a formal collaboration framework since 2003, yes, and they talk regularly through working groups they call "clusters." But publishing unified principles? That's rare.</p>

            <p>It would have been easy to go separate ways. The US regulatory environment is drifting from European frameworks on multiple fronts. The political pressure to "America First" everything is real. EMA could have issued European guidance. FDA could have issued American guidance. Nobody would have blinked.</p>

            <p>Instead, they chose alignment.</p>

            <p>Ten principles. One document. Two logos at the top of the page.</p>

            <p>In a moment when international cooperation is unfashionable, the people responsible for drug safety decided that AI in drug development was too important to fragment. That matters.</p>

            <h2>The Principles Themselves</h2>

            <p>I've been saying for years that AI-supported drug development will meet no different standards than drug development without AI. The scientific method doesn't change because you're using a neural network. Evidence is still evidence. Scrutiny is still scrutiny. The fundamental question—does this drug work, is it safe, do the benefits outweigh the risks—remains exactly the same.</p>

            <p>Reading through the ten principles, I felt validated. Not because the guidance is groundbreaking, but because it isn't.</p>

            <p>Human-centric by design. Risk-based approach. Adherence to standards. Clear context of use. Multidisciplinary expertise. Data governance and documentation. Sound model development practices. Performance assessment. Life cycle management. Clear communication.</p>

            <p>If you've been doing drug development properly, you recognize every single one of these. GxP requirements? Already following them. Documentation and traceability? Already doing it. Risk-based validation? That's ICH Q9. Multidisciplinary teams? That's how good science works.</p>

            <p>The guidance reads like someone wrote down what competent drug development has always looked like, then added "...and this applies to AI too."</p>

            <p>Which is exactly the point.</p>

            <h2>What This Actually Means</h2>

            <p>AI doesn't get a special pass. It doesn't get relaxed standards because the technology is new and exciting. It doesn't get to skip validation because the models are complex. It doesn't get to avoid documentation because "the algorithm figured it out."</p>

            <p>If you use AI to design a protocol, you still need to justify that protocol. If you use AI to identify patients, you still need to demonstrate your selection criteria are valid. If you use AI to predict safety signals, you still need to show your predictions are reliable.</p>

            <p>The burden of proof doesn't disappear. It just has a new tool helping you meet it.</p>

            <p>This is what I meant when I wrote about speed being the path to compliance. The regulators aren't asking you to slow down. They're asking you to be rigorous. Those aren't the same thing.</p>

            <p>AI can help you move faster precisely because it can help you be more rigorous—if you implement it properly. Real-time data monitoring catches problems earlier. Automated consistency checks find errors humans miss. Pattern recognition across thousands of trials surfaces insights no single reviewer could see.</p>

            <p>Speed and rigor aren't opposites. They're partners. The guidance implicitly acknowledges this.</p>

            <h2>The Life Cycle Point</h2>

            <p>One principle deserves particular attention: life cycle management.</p>

            <p>The guidance explicitly calls out data drift—the phenomenon where model performance degrades as real-world data diverges from training data. It requires "scheduled monitoring and periodic re-evaluation."</p>

            <p>This is important because it addresses the biggest practical risk in AI deployment: the assumption that validation is a one-time event.</p>

            <p>It isn't. Models age. Data distributions shift. What worked in 2026 may not work in 2028. The guidance makes clear that regulatory expectation includes ongoing vigilance, not just initial approval.</p>

            <p>For anyone building AI systems in drug development, this means architecture decisions today. You need monitoring infrastructure. You need revalidation protocols. You need to design for change, not just for launch.</p>

            <h2>The Remaining Questions</h2>

            <p>Ten principles don't answer everything.</p>

            <p>What specific validation approaches satisfy "risk-based performance assessment" for different AI applications? The guidance doesn't say. That's deliberate—the field is moving too fast for prescriptive requirements—but it means organizations need to make judgment calls and be prepared to defend them.</p>

            <p>How do you demonstrate "interpretability" for complex models? The guidance requires "plain language" communication about AI limitations and performance, but doesn't define what that looks like for a transformer model with billions of parameters. Practical standards will emerge through experience.</p>

            <p>What happens when FDA and EMA disagree on implementation details? Joint principles don't guarantee joint interpretation. Sponsors operating in both jurisdictions may still face divergent expectations on specifics.</p>

            <p>These aren't criticisms. A principles document can't answer every question. But if you're planning AI implementations, these are the areas where you'll need to think carefully and document your reasoning.</p>

            <h2>What I Take From This</h2>

            <p>The guidance confirms something I've believed for a while: the regulatory framework isn't the obstacle to AI adoption in drug development. Organizational readiness is.</p>

            <p>FDA and EMA have now explicitly said they expect AI to "promote innovation, reduce time-to-market, strengthen regulatory excellence and pharmacovigilance." They've laid out principles that are demanding but achievable. They've done their part.</p>

            <p>The question now is whether organizations will do theirs.</p>

            <p>Do you have the data governance to support AI development? The multidisciplinary teams to implement it responsibly? The monitoring infrastructure to maintain it over time? The documentation practices to demonstrate compliance?</p>

            <p>If not, this guidance tells you what to build. Not because FDA and EMA invented new requirements, but because they've clarified that the old requirements—the ones that always mattered—apply to AI just like everything else.</p>

            <p>The standards haven't changed. The tools have. That's the opportunity.</p>

            <p><em>—Johan Strömquist</em></p>

        </div>

        <!-- Bottom Navigation with Next/Prev (injected dynamically) -->
        <div class="post-nav" id="blog-bottom-nav"></div>
    </article>

    <!-- Footer (injected dynamically) -->
    <div id="blog-footer"></div>

    <!-- Load posts data and layout manager -->
    <script src="posts.js"></script>
    <script src="blog-layout.js"></script>
</body>
</html>
